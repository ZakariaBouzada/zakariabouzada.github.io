<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Automated Medallion Data Pipeline</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XBNCZ4QZPJ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-XBNCZ4QZPJ');
    </script>
    <link rel="stylesheet" href="../../css/style.css">
    <link rel="stylesheet" href="databrickscss/databricks-style.css">
</head>
<body class="pipeline-page">

<header>
    <h1>Automated Medallion Data Pipeline</h1>


    <div class="header-tech-stack">
        <span class="tech-pill databricks">Databricks</span>
        <span class="tech-pill databricks">Medallion Architecture</span>
        <span class="tech-pill databricks">Python</span>
        <span class="tech-pill databricks">SQL</span>
        <span class="tech-pill databricks">Power BI</span>
    </div>
    <nav>
        <a href="../../index.html" class="back-btn">← Back to Home</a>
    </nav>
</header>

<main>

    <!-- ===================== -->
    <!-- PROJECT OVERVIEW -->
    <!-- ===================== -->
    <section>
        <h2>Project Overview</h2>
        <p>
            This project implements a fully automated, end-to-end data pipeline for analyzing
            NBA player performance. Built on Microsoft Databricks using Apache Spark, the pipeline
            follows the <strong>medallion architecture</strong> (Bronze, Silver, Gold) and produces
            analytics-ready datasets that power interactive Power BI dashboards.
        </p>

        <p>
            The focus of the project was on scalable data processing, data quality, automation,
            and clear separation of responsibilities across pipeline layers.
        </p>
    </section>

    <!-- ===================== -->
    <!-- ARCHITECTURE -->
    <!-- ===================== -->
    <section>
        <h2>Pipeline Architecture</h2>
        <p>
            The system follows a layered medallion architecture, where raw data is incrementally
            refined into high-quality analytical datasets.
        </p>

        <!-- IMAGE: architecture diagram -->
        <!-- File location suggestion:
             /assets/images/medallion_architecture.png -->
        <img src="../../projects/databricks-pipeline/images/medallion_architecture.png"
             alt="Medallion architecture diagram"
             style="max-width:100%; margin-top:1rem;">
    </section>

    <!-- ===================== -->
    <!-- PIPELINE LAYERS -->
    <!-- ===================== -->
    <section>
        <h2>Pipeline Layers</h2>

        <h3>Bronze Layer – Data Ingestion</h3>
        <p>
            The ingestion process is fully automated using the <strong>Kaggle API</strong> to programmatically fetch the
            <a href="https://www.kaggle.com/datasets/sumitrodatta/nba-aba-baa-stats" target="_blank" style="color: #0066cc; text-decoration: none; font-weight: 500;">NBA/ABA/BAA Historical Statistics</a>
            dataset. Link from: <code> https://www.kaggle.com/datasets/sumitrodatta.</code>
        </p>
        <p>
            Raw files are ingested into Databricks as <strong>Spark DataFrames</strong>. The Bronze layer preserves the
            original structure of the source data, acting as an immutable "Landing Zone" that allows for
            full traceability and historical reprocessing.
        </p>

        <h3>Silver Layer – Data Cleaning & Transformation</h3>

        <p>
            The Silver layer cleans and standardizes the raw data. Key transformations include
            <strong>removing duplicates</strong>, handling null values, and <strong>normalizing identifiers</strong>
            across multiple seasons. Data is cast into appropriate numeric types, and technical metadata
            (such as transformation timestamps) is added to ensure robust data lineage.
        </p>

        <h3>Gold Layer – Analytics & Aggregation</h3>

        <p>
            In the Gold layer, the data is refined into high-value analytical tables. We calculate complex
            aggregations such as <strong>Points Per Game (PPG)</strong>, <strong>Assists Per Game (APG)</strong>,
            and advanced metrics like <strong>Double-Doubles</strong> and <strong>Triple-Doubles</strong>.
            These datasets are highly optimized for high-performance consumption by the
            <strong>JavaScript Dashboard</strong> and <strong>Power BI</strong>.
        </p>
    </section>

    <!-- ===================== -->
    <!-- ENGINEERING DECISIONS -->
    <!-- ===================== -->
    <section>
        <h2>Design Decisions & Engineering Considerations</h2>
        <ul>
            <li>Apache Spark was chosen for scalable processing and future extensibility.</li>
            <li>Medallion architecture enables data quality enforcement and clear data lineage.</li>
            <li>Aggregations are isolated in the Gold layer to avoid recomputation.</li>
            <li>Batch processing was selected over streaming due to dataset characteristics.</li>
            <li>Delta tables enable reliable Power BI integration.</li>
        </ul>
    </section>

    <!-- ===================== -->
    <!-- DATA QUALITY -->
    <!-- ===================== -->
    <section>
        <h2>Data Quality & Validation</h2>
        <p>
            Multiple data quality checks were implemented throughout the pipeline to ensure
            reliable analytical results:
        </p>
        <ul>
            <li>Deduplication of player records</li>
            <li>Safe casting of numeric fields</li>
            <li>Filtering of invalid or incomplete rows</li>
            <li>Row count logging at each pipeline stage</li>
        </ul>
    </section>

    <!-- ===================== -->
    <!-- RESULTS & VISUALS -->
    <!-- ===================== -->

    <section>
    <h2>Results & Advanced Analytics</h2>

    <div class="project-summary">
        <p>
            The final stage of the <strong>Medallion Pipeline</strong> transforms raw player data into highly optimized <strong>Gold-tier datasets</strong>. To ensure high-performance rendering for the front-end, the processed <code>.csv</code> outputs from Databricks were converted into lightweight <code>.json</code> structures.
        </p>
        <p>
            This language choice allows the <strong>JavaScript-driven dashboard</strong> to fetch and visualize complex player metrics—like triple-double trends and league-wide averages—instantly without server-side lag.
        </p>
    </div>
        <!-- Embedded NBA Dashboard -->
        <div class="nba-dashboard-container">
            <h3>Interactive NBA Analytics Dashboard</h3>
            <p class="sub-text"><em>Integrated View: Interactive Chart.js visuals powered by the Gold-layer JSON data.</em></p>
            <iframe src="../NBA-dashboard/nba-dashboard.html" title="NBA Dashboard" frameborder="0"></iframe>
        </div>

        <p style="text-align:center; margin-top:1rem;">
            <a href="../NBA-dashboard/nba-dashboard.html" target="_blank" class="btn">Open Full NBA Dashboard</a>
        </p>

        <!-- IMAGE: top players by average points -->
        <!-- /projects/images/top10_avg_points.png -->

    <div class="validation-section">
        <h3>Pipeline Validation & Data Quality Checks</h3>
        <p>
            Before the data is exported for the web or external BI tools, I implemented a validation step within the Databricks notebook. Using <strong>Matplotlib</strong> and <strong>Seaborn</strong>, the pipeline generates the following internal visuals to ensure the <strong>Gold Layer</strong> aggregations match the expected distribution and statistical accuracy.
        </p>

        <div class="validation-gallery">
            <figure>
                <img src="images/top10_avg_points.png" alt="Top 10 players by average points">
                <figcaption>Gold summary table as graph: Verifying season scoring averages against all players.</figcaption>
            </figure>

            <figure>
                <img src="images/top10_triple_doubles.png" alt="Top 10 players by triple doubles">
                <figcaption>Advanced Gold summary table as graph: Control: Ensuring advanced count metrics are correctly aggregated across seasons.</figcaption>
            </figure>
        </div>
    </div>
    <!--
         <img src="images/top10_avg_points.png"
             alt="Top 10 players by average points"
             style="max-width:100%; margin-top:1rem;">

        <!- IMAGE: triple / double doubles -->
        <!-- /projects/images/top10_triple_doubles.png
        <img src="images/top10_triple_doubles.png"
             alt="Top 10 players by triple doubles"
             style="max-width:100%; margin-top:1rem;"> */ -->
    </section>

    <!-- ===================== -->
    <!-- POWER BI -->
    <!-- ===================== -->
    <section>
        <h2>Power BI Dashboard</h2>
        <p>
            The final Gold-layer tables are persisted as Delta tables and connected directly
            to Power BI, enabling interactive dashboards and real-time analytical exploration.
        </p>

        <!-- IMAGE: Power BI screenshot -->
        <!-- /projects/images/powerbi_dashboard.png -->
        <img src="images/image.png"
             alt="Power BI dashboard"
             style="max-width:100%; margin-top:1rem;">
    </section>

    <!-- ===================== -->
    <!-- DATA OUTPUTS -->
    <!-- ===================== -->
    <section>
        <h2>Data Outputs</h2>
        <p>
            The pipeline produces analytics-ready CSV datasets that can be used for
            further analysis or visualization.
        </p>
        <ul class="dataset-links">
            <li><a href="data/gold_player_summary.csv" target="_blank">Gold Player Summary (CSV)</a></li>
            <li><a href="data/gold_player_adv_summary.csv" target="_blank">Gold Player Advanced Metrics (CSV)</a></li>
            <li><a href="data/gold_team_summary.csv" target="_blank">Gold Team Summary (CSV)</a></li>
        </ul>
    </section>

    <!-- ===================== -->
    <!-- LIMITATIONS & NEXT STEPS -->
    <!-- ===================== -->
    <section>
        <h2>Limitations & Future Improvements</h2>
        <ul>
            <li>Support incremental loads and streaming ingestion</li>
            <li>Add automated data validation tests</li>
            <li>Implement CI/CD for pipeline deployments</li>
            <li>Extend analytics to include advanced efficiency metrics</li>
        </ul>
    </section>

    <!-- ===================== -->
    <!-- ACADEMIC NOTE -->
    <!-- ===================== -->
    <section>
        <h2>Academic Note</h2>
        <p>
            Due to academic ownership and infrastructure restrictions, the Databricks workspace
            and source code are private. This page documents the system design, methodology,
            and outputs of the project.
        </p>
    </section>
    <script>
        const iframe = document.querySelector('.nba-dashboard-container iframe');

        iframe.style.height = "500px" ;
    </script>

</main>

<footer>
    <p>© 2026 Zakaria Bouzada</p>
</footer>

</body>
</html>
